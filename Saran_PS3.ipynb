{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarannetworkprogammer/Data_foundations/blob/main/Saran_PS3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30_hXHw6_93c"
      },
      "source": [
        "# Problem Set 3\n",
        "\n",
        "For this problem set, you will expand on PS2 to perform and evaluate various sentiment classification methods.\n",
        "\n",
        "Your name: \n",
        "\n",
        "You abc123:\n",
        "\n",
        "## Submission Instructions\n",
        "\n",
        "After completing the exercises below, generate a pdf of the code **with** outputs. After that create a zip file containing both the completed exercise and the generated PDF/HTML. You are **required** to check the PDF/HTML to make sure all the code **and** outputs are clearly visible and easy to read. If your code goes off the page, you should reduce the line size. I generally recommend not going over 80 characters.\n",
        "\n",
        "Finally, name the zip file using a combination of your the assigment and your name, e.g., ps3_rios.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peYqCGK8_93j"
      },
      "source": [
        "## Exercise 1 (1 point)\n",
        "\n",
        "For this step, you will load the training and test sentiment datasets \"twitdata_TEST.tsv\" and \"allTrainingData.tsv\". The data should be loaded into 4 lists of strings: X_txt_train, X_txt_test, y_test, y_train.\n",
        "\n",
        "Note, when using csvreader, you need to pass the \"quoting\" the value csv.QUOTE_NONE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Mhyn4ig3_93l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "00158bca-35d6-4d4d-e418-47592957ddb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8018\n",
            "8018\n",
            "test data\n",
            "3199\n",
            "3199\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "X_txt_train = []\n",
        "y_train = []\n",
        "\n",
        "# Loading data from CSVs.\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/PS3/allTrainingData.tsv\") as file:\n",
        " \n",
        "   tsv_file = csv.reader(file, delimiter=\"\\t\",quoting=csv.QUOTE_NONE)\n",
        "   for line in tsv_file:\n",
        "     X_txt_train.append(line[3])\n",
        "     y_train.append(line[2])\n",
        "\n",
        "\n",
        "print(len(X_txt_train))\n",
        "print(len(y_train))\n",
        "\"\"\"\n",
        "# 1. Load the training datasets into two lists (X_txt_train will be a list of strings; y_train)\n",
        "\n",
        "X_txt_test = ...\n",
        "y_test = ...\n",
        "# 2. Load the test datasets into two lists (X_txt_test will be a list of strings; y_test)\n",
        "\"\"\"\n",
        "X_txt_test = []\n",
        "y_test = []\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/PS3/twitdata_TEST.tsv\") as in_file:\n",
        "\n",
        "  reader = csv.reader(in_file, delimiter=\"\\t\",quoting=csv.QUOTE_NONE)\n",
        "  count = 0\n",
        "  for row in reader:\n",
        "    X_txt_test.append(row[3])\n",
        "    y_test.append(row[2])\n",
        "\n",
        "print(\"test data\")\n",
        "print(len(X_txt_test))\n",
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13KvzQpr_93n"
      },
      "source": [
        "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "CnygHJ0E_93o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4a0bc526-ebfc-4b28-e162-5b596f63c35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asserts Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "assert(type(X_txt_train) == type(list()))\n",
        "assert(type(X_txt_train[0]) == type(str()))\n",
        "assert(type(X_txt_test) == type(list()))\n",
        "assert(type(X_txt_test[0]) == type(str()))\n",
        "assert(type(y_test) == type(list()))\n",
        "assert(type(y_train) == type(list()))\n",
        "assert(len(X_txt_test) == 3199)\n",
        "assert(len(y_test) == 3199)\n",
        "assert(len(X_txt_train) == 8018)\n",
        "assert(len(y_train) == 8018)\n",
        "print(\"Asserts Completed Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeXAwaae_93p"
      },
      "source": [
        "## Exercise 2 (2 point)\n",
        "\n",
        "This part is similar to HW2 (using the positive_words and negative_words variables). We will compare last homework's lexicon-based classification method with supervised models. Only make predictions on the test split and store all predictions in the list lex_test_preds. Next, calculate the **macro** precision, macro recall, and macro f1 scores using the lex_test_preds list.\n",
        "\n",
        "You can learn more about lexicon-based classification in Chapter 19.6. If you are interested, the chapter is available online for free at the following link: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/19.pdf)\n",
        "\n",
        "Also, note that I have wrote the code for this exercise, you job is to read the code, understand it, and apply it to make the predictions.\n",
        "\n",
        "**INTUITION:** For PS2 you implemented a \"lexicon-based classifier\". You looked at a few examples and manually accessed it's performance. Howeover, that was arbitary. Now we want to see how well it actually works. Hence, in this homework (for this exercise), you will use the class I provided that implements the lexicon-based classifier and use the provided \"annotatoed dataset\" (loaded in Exercise 1) to see how well it performance. If it worked 100\\% accurately, the F1 would be 1.00. However, it does not, so you should expect a smaller score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nQdjQ0S2_93r"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "class LexiconClassifier():\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "            Initalize the Lexicon classifer by loading lexicons. \n",
        "        \"\"\"\n",
        "        self.positive_words = set()\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/PS3/positive-words.txt', encoding = 'utf-8') as iFile:\n",
        "            for row in iFile:\n",
        "                self.positive_words.add(row.strip())\n",
        "\n",
        "        self.negative_words = set()\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/PS3/negative-words.txt', encoding='iso-8859-1') as iFile:\n",
        "            for row in iFile:\n",
        "                self.negative_words.add(row.strip())\n",
        "\n",
        "    def predict(self, sentence):\n",
        "        \"\"\"\n",
        "            Returns a sentiment prediction give an input string.\n",
        "            \n",
        "            Keyword arguments:\n",
        "            sentence -- string (e.g., \"This is good good good\")\n",
        "            \n",
        "            Returns:\n",
        "            pred -- a string (\"postive, \"negative\", or \"neutral\")\n",
        "        \"\"\"\n",
        "        num_pos_words = 0\n",
        "        num_neg_words = 0\n",
        "        for word in sentence.lower().split():\n",
        "            if word in self.positive_words:\n",
        "                num_pos_words += 1\n",
        "            elif word in self.negative_words:\n",
        "                num_neg_words += 1\n",
        "        \n",
        "        pred = 'neutral'        \n",
        "        if num_pos_words > num_neg_words:\n",
        "            pred = 'positive'\n",
        "        elif num_pos_words < num_neg_words:\n",
        "            pred = 'negative'\n",
        "            \n",
        "        return pred\n",
        "    \n",
        "    def count_pos_words(self, sentence):\n",
        "        \"\"\"\n",
        "            Returns the number of positive words in string\n",
        "            \n",
        "            Keyword arguments:\n",
        "            sentence -- string (e.g., \"This is good good good\")\n",
        "            \n",
        "            Returns:\n",
        "            pred -- an integer (e.g., 3)\n",
        "        \"\"\"\n",
        "        num_pos_words = 0\n",
        "        for word in sentence.lower().split():\n",
        "            if word in self.positive_words:\n",
        "                num_pos_words += 1\n",
        "        return num_pos_words\n",
        "\n",
        "    def count_neg_words(self, sentence):\n",
        "        \"\"\"\n",
        "            Returns the number of negative words in string\n",
        "            \n",
        "            Keyword arguments:\n",
        "            sentence -- string (e.g., \"This is good good good\")\n",
        "            \n",
        "            Returns:\n",
        "            pred -- an integer (e.g., 3)\n",
        "        \"\"\"\n",
        "        num_neg_words = 0\n",
        "        for word in sentence.lower().split():\n",
        "            if word in self.negative_words:\n",
        "                num_neg_words += 1\n",
        "        return num_neg_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IHzizhsm_93s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "78837a40-b49c-4adf-916d-0d4bedf78e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3199\n",
            "Precision: 0.5504\n",
            "Recall: 0.5446\n",
            "F1: 0.5455\n"
          ]
        }
      ],
      "source": [
        "# WRITE CODE HERE\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Instatiate that class\n",
        "\n",
        "lexicon_classifier = LexiconClassifier()\n",
        "\n",
        "lex_test_preds = [] # Initialize this as an empty list\n",
        "\n",
        "# Loop over X_txt_test\n",
        "#    for each string in X_txt_test (i.e., for each item in the list), pass it to LexiconClassifiers .predict() method\n",
        "#    append the prediction to lex_test_preds\n",
        "count = 0\n",
        "for each in X_txt_test:\n",
        "\n",
        "  prediction = lexicon_classifier.predict(each)\n",
        "  lex_test_preds.append(prediction)\n",
        "  #print(each)\n",
        "  #count = count + 1\n",
        "  #if count == 2:\n",
        "    #break\n",
        "\n",
        "\n",
        "print(len(lex_test_preds))\n",
        "\n",
        "precision = precision_score(y_test, lex_test_preds, average='macro')            # Get scores using lex_test_preds and y_test with the precision_score method\n",
        "recall =  recall_score(y_test, lex_test_preds, average='macro')                 # Get scores using lex_test_preds and y_test with the recall_score method\n",
        "f1 = f1_score(y_test, lex_test_preds, average='macro')                          # Get scores using lex_test_preds and y_test with the f1_score method\n",
        "\n",
        "\n",
        "\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFkLCoKf_93t"
      },
      "source": [
        "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N5Stjc9e_93u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6bd15368-2428-4bec-ba3c-399872122a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asserts Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "assert(type(lex_test_preds) == type(list()))\n",
        "assert(type(lex_test_preds[0]) == type(str()))\n",
        "assert(set(lex_test_preds) == set([\"positive\", \"negative\", \"neutral\"]))\n",
        "assert(len(lex_test_preds) == len(y_test))\n",
        "assert(type(precision) == type(float()) or type(precision) == type(np.float64()))\n",
        "assert(type(recall) == type(float()) or type(recall) == type(np.float64()))\n",
        "assert(type(f1) == type(float()) or type(f1) == type(np.float64()))\n",
        "print(\"Asserts Completed Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeh7Torq_93u"
      },
      "source": [
        "## Exercise 3 (1 point)\n",
        "\n",
        "Again, using the LexiconClassifier, write code to generate a lists of lists where each sublist contains the number of positive words and negative words in a tweet. For example, assume we are given the following train and test datasets\n",
        "\n",
        "``` python\n",
        "X_txt_train = [\"good good\", \"bad bad\"]\n",
        "X_txt_test = [\"great\", \"bad bad great\"]\n",
        "```\n",
        "\n",
        "you should write code that creates two lists of lists as follows:\n",
        "\n",
        "``` python\n",
        "X_train_lexicon_features = [[2, 0], [0,2]] # [2, 0] means the first tweeta has 2 positive words and 0 negative words.\n",
        "X_test_lexicon_features = [[1, 0], [1, 2]]\n",
        "```\n",
        "\n",
        "Why are we doing this? We will use these as addition features in Exercise 5, combining it with the ngram features. Combining different sets of features is called \"Feature Engineering\" and is one of the most important steps of many machine learning tasks. In this case, we are using the lexicons to generate additional features. But, we could also count the number of capitalized words, number of punctuation marks, etc. We would come up with different feature sets via trial-and-error. We can guess what type of features would help our task. For instance, for sentiment prediction, we may guess that having many capitalized words is predictive of something negative (e.g., \"WHY ARE YOU DOING THIS!!!!!\").\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1Wc-cA7__93v"
      },
      "outputs": [],
      "source": [
        "# WRITE CODE HERE\n",
        "\n",
        "X_train_lexicon_features = [] # Initailze to an empty list. This will be a list of lists\n",
        "X_test_lexicon_features = [] #  Initailze to an empty list. This will be a list of lists\n",
        "\n",
        "# Loop over X_txt_test\n",
        "#    for each string in X_txt_test (i.e., for each item in the list), pass it to LexiconClassifiers .count_pos_words() and count_neg_words method\n",
        "#    append a list with the counts to X_test_lexicon_features\n",
        "\n",
        "test =[]\n",
        "for each in X_txt_test:\n",
        "\n",
        "  count = count + 1\n",
        "  \n",
        "  pos= lexicon_classifier.count_pos_words(each)\n",
        "  neg = lexicon_classifier.count_neg_words(each)\n",
        "  X_test_lexicon_features.append([pos,neg])\n",
        "\n",
        "\n",
        "\n",
        "# Loop over X_txt_train\n",
        "#    for each string in X_txt_train (i.e., for each item in the list), pass it to LexiconClassifiers .count_pos_words() and count_neg_words method\n",
        "#    append a list with the counts to X_train_lexicon_features\n",
        "\n",
        "\n",
        "for each in X_txt_train:\n",
        "\n",
        "  count = count + 1\n",
        "  \n",
        "  pos1= lexicon_classifier.count_pos_words(each)\n",
        "  neg1 = lexicon_classifier.count_neg_words(each)\n",
        "  X_train_lexicon_features.append([pos1,neg1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1qCHJP_93v"
      },
      "source": [
        "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m2iPCOOt_93w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1823d337-d319-4553-c503-23dbe43e1181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asserts Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "assert(type(X_train_lexicon_features) == type(list()))\n",
        "assert(type(X_test_lexicon_features) == type(list()))\n",
        "assert(type(X_test_lexicon_features[0]) == type(list()))\n",
        "assert(len(X_train_lexicon_features) == len(X_txt_train))\n",
        "assert(len(X_test_lexicon_features) == len(X_txt_test))\n",
        "assert(len(X_train_lexicon_features[0]) == 2)\n",
        "assert(len(X_test_lexicon_features[0]) == 2)\n",
        "print(\"Asserts Completed Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btUxnPML_93w"
      },
      "source": [
        "## Exercise 4 (2 points)\n",
        "\n",
        "For this task you should creat a feature matrix using CountVectorizer and train a LinearSVC model from scikit-learn. On the train split, use GridSearchCV to find the best LinearSVC C values (0.0001, 0.001, 0.001, 0.01, 0.1, 1, 10, or 100) based on the **macro** f1 scoring metric (hint: \"macro\" average) and set the cv parameter to 5. Also, with the CountVectorizer, only use unigrams (i.e., set ngram_range = (1,1)). Note that GridSearchCV will retrain the final classifier using the best parameters, so you don't need to do it manually.\n",
        "\n",
        "**INTUITION:** For this exercise, you are implementing a simple linear model using bag-of-words features. This is generally a very strong and simple baseline for text classification. Compare the scores from this exercise to the results in Exercise 2. You will find that the machine learning-based model implemented here acheives better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n6kd9XYo_93w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ce0cf6d6-ad1c-498e-cf10-5f2dfe7cfa28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes\n",
            "(8018, 20864)\n",
            "(3199, 20864)\n",
            "Validation F1: 0.5921\n",
            "Precision: 0.6525\n",
            "Recall: 0.5740\n",
            "F1: 0.5878\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "### warning disabling\n",
        "\n",
        "from warnings import simplefilter\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "\n",
        "# WRITE CODE HERE\n",
        "\n",
        "# Summary:\n",
        "# 1. Convert X_txt_train and X_txt_test to matricies of numbers (i.e., use CountVectorizer)\n",
        "\n",
        "vec = CountVectorizer(ngram_range=(1,1))\n",
        "\n",
        "X_train = vec.fit_transform(X_txt_train) # This should be a matrix\n",
        "X_test = vec.transform(X_txt_test)   # This should be a matrix\n",
        "\n",
        "\n",
        "print(\"shapes\")\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "# Initialize the classifier LinearSVC \n",
        "\n",
        "model = LinearSVC()\n",
        "\n",
        "# Create the params with the C values\n",
        "\n",
        "params = {\"C\": [0.0001, 0.001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(model, param_grid=params, cv=5, scoring='f1_macro')\n",
        "\n",
        "# \"fit\" the model  on X_train\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "validation_score = clf.best_score_  # Get the score from the GridSearchCV \"best score\"\n",
        "\n",
        "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
        "\n",
        "svm_test_predictions =  clf.predict(X_test) # \"predict\" on X_test \n",
        "\n",
        "precision = precision_score(y_test, svm_test_predictions, average='macro')  # Get scores using svm_test_predictions and y_test with the precision_score method\n",
        "recall = recall_score(y_test, svm_test_predictions, average='macro')\n",
        "f1 = f1_score(y_test, svm_test_predictions, average='macro')\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0paBcH1_93x"
      },
      "source": [
        "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VuyQ8_El_93x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a309a186-b0c7-4339-fd50-7e96aa53a17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asserts Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "assert(type(X_train) == type(csr_matrix(0)) or type(X_train) == type(np.array(0)))\n",
        "assert(type(X_test) == type(csr_matrix(0)) or type(X_test) == type(np.array(0)))\n",
        "assert(X_train.shape[0] == len(X_txt_train))\n",
        "assert(X_test.shape[0] == len(X_txt_test))\n",
        "assert(X_train.shape[1] == X_test.shape[1])\n",
        "assert(type(precision) == type(float()) or type(precision) == type(np.float64()))\n",
        "assert(type(recall) == type(float()) or type(recall) == type(np.float64()))\n",
        "assert(type(f1) == type(float()) or type(f1) == type(np.float64()))\n",
        "print(\"Asserts Completed Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz8zklBA_93y"
      },
      "source": [
        "## Exercise 5 (2 points)\n",
        "\n",
        "Repeat the experiment from exercise 4, but include the lexicon features (from exercise 3) with the CountVectorizer features. Specifically, you need to concatenate the variables ```X_train_lexicon_features``` and ```X_test_lexicon_features``` with ```X_train``` and ```X_test```, respectively. Intuitively, we are performing feature engineering by adding \"lexicon features\".\n",
        "\n",
        "HINT: You will need to convert the lexicon features to numpy arrays then call hstack from the scipy.sparse library (https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.hstack.html)\n",
        "\n",
        "```python\n",
        "    from scipy.sparse import hstack\n",
        "    new_matrix = hstack([ngram_matrix, lexicon_matrix])\n",
        "```\n",
        "\n",
        "Again, this is a \"Feature Engineering\" exercise. This is common in all machine learning tasks.\n",
        "\n",
        "**INTUITION:** How do we improve the model Exercise 4? You could try different machine learning models. However, it is generally better to focus on feature engineering. What information can you provide the model to make better predictions? Here we will try to combine counts using the Lexicon from Exercise 3 as additional features (i.e., combined with the bag-of-word features) from Exercise 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XkExUrIr_93y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2dfdd341-270e-4602-ee24-8de47aaf2ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1: 0.6008\n",
            "Precision: 0.6617\n",
            "Recall: 0.5977\n",
            "F1: 0.6124\n"
          ]
        }
      ],
      "source": [
        "import scipy.sparse as sp\n",
        "from scipy.sparse import hstack\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# WRITE CODE HERE\n",
        "\n",
        "\n",
        "# Summary:\n",
        "# 1. Convert X_txt_train and X_txt_test to matricies of numbers (i.e., use CountVectorizer)\n",
        "\n",
        "vec2 = CountVectorizer(ngram_range=(1,1))\n",
        "\n",
        "X_train_w_lex = vec2.fit_transform(X_txt_train) # This will be the matrix from CountVectorizer (X_txt_train)\n",
        "X_test_w_lex = vec2.transform(X_txt_test)\n",
        "\n",
        "# Now we need to convert X_train_lexicon_features and X_test_lexicon_features to numpy arrays\n",
        "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
        "X_test_lexicon_features = np.array(X_test_lexicon_features)\n",
        "\n",
        "# \"hstack\" X_train_lexicon_features with X_train_w_lex\n",
        "# \"hstack\" X_test_lexicon_features with X_test_w_lex\n",
        "\n",
        "X_train_w_lex =  hstack([X_train_lexicon_features, X_train_w_lex])\n",
        "X_test_w_lex  = hstack([X_test_lexicon_features,X_test_w_lex])\n",
        "\n",
        "# Initialize the classifier LinearSVC \n",
        "\n",
        "model = LinearSVC()\n",
        "\n",
        "# Create the params with the C values\n",
        "\n",
        "params = {\"C\": [0.0001, 0.001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(model, param_grid=params, cv=4, scoring='f1_macro')\n",
        "\n",
        "# \"fit\" the model  on X_train_w_lex\n",
        "\n",
        "clf.fit(X_train_w_lex,y_train)\n",
        "\n",
        "validation_score = clf.best_score_ \n",
        "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
        "\n",
        "svm_lex_test_predictions =  clf.predict(X_test_w_lex )  # Get predictions on X_test_w_lex\n",
        "\n",
        "precision = precision_score(y_test, svm_lex_test_predictions , average='macro')  # Get scores using svm_test_predictions and y_test with the precision_score method\n",
        "recall = recall_score(y_test, svm_lex_test_predictions, average='macro')\n",
        "f1 = f1_score(y_test, svm_lex_test_predictions, average='macro')\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugMycYtx_93y"
      },
      "source": [
        "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m8PpY6Jm_93z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cc289dc4-1517-44d8-be48-d4b669283e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asserts Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "assert(X_train_w_lex.shape[0] == len(X_txt_train))\n",
        "assert(X_test.shape[0] == len(X_txt_test))\n",
        "assert(X_train_w_lex.shape[1] == X_test.shape[1] + 2)\n",
        "assert(X_train_w_lex.shape[1] == X_test_w_lex.shape[1])\n",
        "assert(type(precision) == type(float()) or type(precision) == type(np.float64()))\n",
        "assert(type(recall) == type(float()) or type(recall) == type(np.float64()))\n",
        "assert(type(f1) == type(float()) or type(f1) == type(np.float64()))\n",
        "print(\"Asserts Completed Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCuRcqKY_93z"
      },
      "source": [
        "## Exercise 6 (1 point)\n",
        "\n",
        "For this exercise, you will perform manual analysis of the predictions. Answer the questions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-JKHOGWy_930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1747fe6f-4ba1-451b-b942-67c0b6cf6704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: Musical awareness: Great Big Beautiful Tomorrow has an ending, Now is the time does not\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: positive\n",
            "SVM+Lexicon Prediction: positive\n",
            "Lexicon Model Prediction: positive\n",
            "\n",
            "Tweet: On Radio786 100.4fm 7:10 Fri Oct 19 Labour analyst Shawn Hattingh: Cosatu's role in the context of unrest in the mining http://t.co/46pjzzl6\n",
            "Ground-Truth Class: neutral\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: negative\n",
            "\n",
            "Tweet: Kapan sih lo ngebuktiin,jan ngomong doang Susah Susah.usaha Aja blm udh nyerah,inget.if you never try you'll never know.cowok kok gentle bgt\n",
            "Ground-Truth Class: negative\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: positive\n",
            "\n",
            "Tweet: Tomorrow come and hear @DavidWillettsMP&amp;@MASieghart debate \"Navigating the new Higher Education market\" 5.30pm, Jurys Inn #CPC12\n",
            "Ground-Truth Class: neutral\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: Excuse the connectivity of this live stream, from Baba Amr, so many activists using only one Sat Modem. LIVE http://t.co/U283IhZ5 #Homs\n",
            "Ground-Truth Class: neutral\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: negative\n",
            "\n",
            "Tweet: Show your LOVE for your local field &amp; it might win an award!  Gallagher Park #Bedlington current 4th in National Award http://t.co/WeiMDtQt\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: positive\n",
            "SVM+Lexicon Prediction: positive\n",
            "Lexicon Model Prediction: positive\n",
            "\n",
            "Tweet: @firecore Can you tell me when an update for the Apple TV 3rd gen becomes available? The missing update holds me back from buying #appletv3\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: @Heavensbasement The Crown, Filthy McNastys, Katy Dalys or the Duke if York in Belfast! Can't wait to catch you guys tomorrow night!\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: negative\n",
            "\n",
            "Tweet: Uncover the Eternal City! Return flights to Rome travel on the 21st January, for 3 nights Augustea, 3 star Hotel... http://t.co/tw0Jeh9g\n",
            "Ground-Truth Class: neutral\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: My #cre blog Oklahoma Per Square Foot returns to the @JournalRecord blog hub tomorrow. I will have some interesting local data to share.\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: positive\n",
            "SVM+Lexicon Prediction: positive\n",
            "Lexicon Model Prediction: positive\n",
            "\n",
            "Tweet: \"@bbcburnsy: Loads from SB; talks with Chester continue; no deals 4 out of contract players 'til Jan; Dev t Roth ,Coops to Chest'ld #hcafc\"\n",
            "Ground-Truth Class: negative\n",
            "SVM Prediction: negative\n",
            "SVM+Lexicon Prediction: negative\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: Trey Burke has been suspended for the Northern Michigan game (exhibition) tomorrow. http://t.co/oefkAElW\n",
            "Ground-Truth Class: negative\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: W.O.W Wednesday!Marni lands this Lumberjack vest for the ladies looking to bring a little Tom boy toughness  http://t.co/7NyCbdJR\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: positive\n",
            "SVM+Lexicon Prediction: positive\n",
            "Lexicon Model Prediction: negative\n",
            "\n",
            "Tweet: Activists in Deir Ezzor captured this image of Musab Bin Umair Mosque after regime forces set it on fire Wednesday. http://t.co/MRcoprCE\n",
            "Ground-Truth Class: negative\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: @karaotr You will appreciate this.. Sunday brunch coffee: Normal cup in b/g and then the BOWL of java. Yowza. http://t.co/XhbtaCvm\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: positive\n",
            "SVM+Lexicon Prediction: positive\n",
            "Lexicon Model Prediction: positive\n",
            "\n",
            "Tweet: Join me Wed for a live webcast on cost optimization for IT, for the SMB crowd. http://t.co/tyJn4RES  &lt;&lt; send your questions in! #DellWebcast\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: Special THANKS to EVERYONE for coming out to Taboo Tuesday With DST tonight! It was FUN&amp;educational!!! :) @XiEtaDST\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: positive\n",
            "SVM+Lexicon Prediction: positive\n",
            "Lexicon Model Prediction: negative\n",
            "\n",
            "Tweet: @fatimasule That was the revelation I mentioned on sunday evening. I am still in Abj. How are u &amp; where have u been again?\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: positive\n",
            "\n",
            "Tweet: Kim Hyung Jun - Football Team the 2nd A Match at YeongDeungPo-gu DaeRimDong [12.10.27] Credit : tlxhah #6 http://t.co/u7mPTl0X\n",
            "Ground-Truth Class: neutral\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n",
            "Tweet: The audio booth is ready to blow the roof off the Comcast Center tomorrow! Are you? #MDMadness http://t.co/B19fECgY\n",
            "Ground-Truth Class: positive\n",
            "SVM Prediction: neutral\n",
            "SVM+Lexicon Prediction: neutral\n",
            "Lexicon Model Prediction: neutral\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_tweets = 0\n",
        "for text, svm_pred, svm_lex_pred, lex_pred, y  in zip(X_txt_test, svm_test_predictions, svm_lex_test_predictions, lex_test_preds, y_test):\n",
        "    print(\"Tweet: {}\".format(text))\n",
        "    print(\"Ground-Truth Class: {}\".format(y))\n",
        "    print(\"SVM Prediction: {}\".format(svm_pred))\n",
        "    print(\"SVM+Lexicon Prediction: {}\".format(svm_lex_pred))\n",
        "    print(\"Lexicon Model Prediction: {}\".format(lex_pred))\n",
        "    print()\n",
        "    \n",
        "    num_tweets += 1\n",
        "    if num_tweets == 20:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH21SZ_q_930"
      },
      "source": [
        "Manually annotate all of the tweets printed above:\n",
        "   1. Tweet 1 Annotation Here: Positive\n",
        "   1. Tweet 2 Annotation Here: Negative\n",
        "   1. Tweet 3 Annotation Here: Neutral\n",
        "   1. Tweet 4 Annotation Here: Negative\n",
        "   1. Tweet 5 Annotation Here: Negative\n",
        "   1. Tweet 6 Annotation Here: Neutral\n",
        "   1. Tweet 7 Annotation Here: Neutral\n",
        "   1. Tweet 8 Annotation Here: Neutral\n",
        "   1. Tweet 9 Annotation Here: Positive\n",
        "   1. Tweet 10 Annotation Here: Positive\n",
        "   1. Tweet 11 Annotation Here: Neutral\n",
        "   1. Tweet 12 Annotation Here: Neutral\n",
        "   1. Tweet 13 Annotation Here: Positive\n",
        "   1. Tweet 14 Annotation Here: Positive\n",
        "   1. Tweet 15 Annotation Here: Positive\n",
        "   1. Tweet 16 Annotation Here: Positive\n",
        "   1. Tweet 17 Annotation Here: Neutral\n",
        "   1. Tweet 18 Annotation Here: Neutral\n",
        "   1. Tweet 19 Annotation Here: Positive\n",
        "   1. Tweet 20 Annotation Here: Positive\n",
        "\n",
        "- How many of your annotations match the ground truth labels? Do you think the datasets labels are correct? (Use your intuition)\n",
        "    - Most of them are matched except three. Yeah i think dataset labels are correct.\n",
        "\n",
        "- How many of your annotations match the lexicon-based model's predictions?\n",
        "    - 12 of my annotations mathced with lexicon based models's predictions.\n",
        "\n",
        "- How many of your annotations match the SVM's predictions?\n",
        "    - 13 of my annotations matchedd with my SVM's predictions.\n",
        "    \n",
        "- How many of your annotations match the SVM+Lexicon's predictions?\n",
        "    - 14 of my annotations matched with SVM+Lexicon predictions.\n",
        "    \n",
        "- Do you see any major limitations of the linear SVM model? Use your intuition, I will accept most answers, as long as it makes some sense. Please describe and provide examples below:\n",
        "\n",
        "\n",
        "Disadvantages:\n",
        "SVM algorithm is not suitable for large data sets.\n",
        "SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
        "In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
        "As the support vector classifier works by putting data points, above and below the classifying hyperplane there is no probabilistic explanation for the classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSAMqdfB_930"
      },
      "source": [
        "## Exercise 6 (1 point)\n",
        "\n",
        "For this exercise, you should come up with 10 other potential features that could be useful for sentiment analysis. You do not need to implement them. You simply need to list this. Make sure it is easy for me to understand the feature you describe. An example could be \"The count of the number of capitalized words in the text\".\n",
        "\n",
        "1. Count number of captalized words\n",
        "2. Counting all positive words\n",
        "3. coutning negative words\n",
        "4. score of postive and negative word\n",
        "5. checking not before positive words\n",
        "6. whether it is opinion or suggestion\n",
        "7. Neutral statements\n",
        "8. factual or personal feeling\n",
        "9. Multilingual sentiment analysis\n",
        "10. aspect-based"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oFdTXK1_930"
      },
      "source": [
        "## Extra Credit 1 (2 points)\n",
        "\n",
        "For this extra credit the only goal is to improve your model on the test set (i.e., increase the **macro** f1 score). You may create new features, grid search over more parameters, try different feature weighting methods (e.g., TfidfVectorizer), or test different machine learning models. You can do whatever you want as long as the final test score improves, I will provide you with the extra credit points.\n",
        "\n",
        "DO NOT TRAIN ON THE TEST SET. That is cheating!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6QxvSL_I_930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "931f9f71-eab6-4252-b154-91533baa618a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8018, 20586)\n",
            "(3199, 20586)\n",
            "Validation F1: 0.5762\n",
            "Precision: 0.6423\n",
            "Recall: 0.5658\n",
            "F1: 0.5788\n"
          ]
        }
      ],
      "source": [
        "# WRITE CODE HERE\n",
        "# Here Im using tf-idf vectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vec = TfidfVectorizer(analyzer='word' , stop_words='english',)\n",
        "\n",
        "X_train = vec.fit_transform(X_txt_train) # This should be a matrix\n",
        "X_test = vec.transform(X_txt_test)   # This should be a matrix\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "model = LinearSVC()\n",
        "\n",
        "# Create the params with the C values\n",
        "\n",
        "params = {\"C\": [0.0001, 0.001, 0.001, 0.01, 0.1, 1, 10,100]}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(model, param_grid=params, cv=5, scoring='f1_macro')\n",
        "\n",
        "# \"fit\" the model  on X_train\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "validation_score = clf.best_score_  # Get the score from the GridSearchCV \"best score\"\n",
        "\n",
        "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
        "\n",
        "svm_test_predictions =  clf.predict(X_test) # \"predict\" on X_test \n",
        "\n",
        "precision = precision_score(y_test, svm_test_predictions, average='macro')  # Get scores using svm_test_predictions and y_test with the precision_score method\n",
        "recall = recall_score(y_test, svm_test_predictions, average='macro')\n",
        "f1 = f1_score(y_test, svm_test_predictions, average='macro')\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1: {:.4f}\".format(f1))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}