{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarannetworkprogammer/Data_foundations/blob/main/Saran_Week_9_Lab_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02J3jfwEBqf4"
      },
      "source": [
        "# Machine Learning and NLP\n",
        "\n",
        "Name: Saranchowdary M\n",
        "\n",
        "abc123: pkb378\n",
        "\n",
        "Blank notebook to be used for class exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjISJyc5BqgB"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Write code to load the data in the \"iris.csv\" into numpy arrays.\n",
        "\n",
        "The frst 4 columns are the features/attributes. The last column is the\n",
        "class. Simply load the class as a list of strings. Don't forget to convert the\n",
        "dataset into a numpy array. You can use either DictVectorizer or the CSV\n",
        "method on the previous slide to load the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYprayrvCp67",
        "outputId": "f09a645d-7fa4-4ef5-8713-d6dca86eb25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7WnpVzvBqgE",
        "outputId": "9ba4be01-5310-450d-93e4-447efd291b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.1,3.5,1.4,0.2,Iris-setosa\n",
            "4.9,3.0,1.4,0.2,Iris-setosa\n",
            "4.7,3.2,1.3,0.2,Iris-setosa\n",
            "4.6,3.1,1.5,0.2,Iris-setosa\n",
            "5.0,3.6,1.4,0.2,Iris-setosa\n",
            "5.4,3.9,1.7,0.4,Iris-setosa\n",
            "4.6,3.4,1.4,0.3,Iris-setosa\n",
            "5.0,3.4,1.5,0.2,Iris-setosa\n",
            "4.4,2.9,1.4,0.2,Iris-setosa\n",
            "4.9,3.1,1.5,0.1,Iris-setosa\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/week-9-lab/iris.csv\") as in_file:\n",
        "    count = 0\n",
        "    for row in in_file:\n",
        "        print(row.strip())\n",
        "        count += 1\n",
        "        if count == 10:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLX8jcx8BqgL",
        "outputId": "1608ee59-164c-46fe-d1a6-c66cc4b28c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150,)\n",
            "(150, 4)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "import csv\n",
        "# Write code here\n",
        "# method 1 numpy arrary casting\n",
        "\n",
        "\n",
        "X = []\n",
        "y= []\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/week-9-lab/iris.csv\") as in_file:\n",
        "  iCSV = csv.reader(in_file, delimiter=',')\n",
        "  for row in iCSV:\n",
        "    tmp =[]\n",
        "    for f in row[:-1]:\n",
        "      tmp.append(float(f))  \n",
        "    X.append(tmp)\n",
        "    y.append(row[-1])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvYzCfVsETfp"
      },
      "outputs": [],
      "source": [
        "vec = DictVectorizer()\n",
        "\n",
        "X_dicts = []\n",
        "y = []\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/week-9-lab/iris.csv\") as in_file:\n",
        "  iCSV = csv.reader(in_file, delimiter=',')\n",
        "  for row in iCSV:\n",
        "    tmp = {\"f0\": float(row[0]),\n",
        "           \"f1\": float(row[1]),\n",
        "           \"f2\": float(row[2]),\n",
        "           \"f3\": float(row[3])}\n",
        "\n",
        "    X_dicts.append(tmp)\n",
        "\n",
        "    y.append(row[-1])\n",
        "    \n",
        "     \n",
        "X = vec.fit_transform(X_dicts)\n",
        "y  = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbESpR6GF1s-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJgq9_ZyBqgN"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "Using the iris data you loaded in Exercise 1, do the following:\n",
        "\n",
        "- Use train_test_split() to divide the iris dataset. (use 0.2 for the\n",
        "test size). Set random_state to 42.\n",
        "- Train an SVM on the train split and evaluate using accuracy on the\n",
        "test split.\n",
        "- Fiddle with the parameters of the SVM to see how it effects the\n",
        "performance.\n",
        "- Calculate the accuracy on the train split. Is there a difference between the train/test accuracies?\n",
        "\n",
        "Next, try using a different classifier, a random forest, and see how it\n",
        "compares to the SVM\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "Note that this is a toy dataset, so all scores will be high."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZNQokjMBqgP",
        "outputId": "56f2c1a8-d771-4092-d0d5-0d3a8259d760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(75, 4) (75, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Write code here\n",
        "\n",
        "\n",
        "X_train , X_val , y_train, y_val = train_test_split(X,y, test_size =0.5)\n",
        "\n",
        "print(X_train.shape, X_val.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXQeIXEiPZvr",
        "outputId": "d88071a5-cbed-4ad3-b59c-78cf518121b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.96\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(C=100.0)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "preds = clf.predict(X_val)\n",
        "\n",
        "print(accuracy_score(y_val,preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6RxjSHOP1pq",
        "outputId": "f2b31571-d3a5-4ff1-edf4-8a3ca5815e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9866666666666667\n"
          ]
        }
      ],
      "source": [
        "preds = clf.predict(X_train)\n",
        "\n",
        "print(accuracy_score(y_train,preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW7SHZOiBqgR"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "Using the train/test iris dataset split from exercise 2. Train a model on the training dataset using GridSearchCV with the SVC kernel parameters \"rbf\" and \"linear\",and C parameters 0.001, 0.01, 0.1, 1., and 10. Print the training and\n",
        "validation scores for the best set of parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyPcXrFwBqgS",
        "outputId": "080e0ef3-f5a9-431a-cf30-235ab7402650"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=SVC(),\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
              "                         'kernel': ['rbf', 'linear']})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write code here\n",
        "\n",
        "\n",
        "X_train , X_test , y_train, y_test = train_test_split(X,y, test_size =0.5)\n",
        "\n",
        "svc = SVC()\n",
        "\n",
        "params = {'kernel': ['rbf','linear'], 'C':[0.001,0.01,0.1, 1.0,10.]}\n",
        "\n",
        "clf = GridSearchCV(svc, params, cv=3)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbPhORUzU6iF",
        "outputId": "a3faab65-1f17-4260-f6e2-42509bcfaa62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9733333333333333"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkHHDeRcU9cZ",
        "outputId": "1e80dd31-cb29-474a-a788-02ec1ab6df4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9733333333333334\n"
          ]
        }
      ],
      "source": [
        "preds = clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSwazg2HBqgU"
      },
      "source": [
        "## Exercise 4\n",
        "\n",
        "The tab (\\t) separated file \"sentiment-twitter-data.tsv\" contains tweets annotated for sentiment. Load the data then do the following:\n",
        "\n",
        "- split the dataset into a train/test split.\n",
        "- create a bag of words feature representation for the tweets using the CountVectorizer\n",
        "- Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier. Only test 2 C values to reduce overhead (0.1 and 1.). Also, use a 2-fold CV, i.e., cv=2.\n",
        "- report (print) the accuracy, micro F1, and macro F1 of the final classifier on the test data and train data\n",
        "- How many features were created with the bag of words representation?\n",
        "\n",
        "file path: ./sentiment-twitter-data.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RGiZ2zssBqgW",
        "outputId": "b24086b4-1d7c-45ee-ca10-eef487f1e616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "264183816548130816\t15140428\tpositive\tGas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n",
            "264249301910310912\t18516728\tnegative\tIranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\n",
            "264105751826538497\t147088367\tpositive\twith J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.\n",
            "264094586689953794\t332474633\tnegative\tTalking about ACT's &amp;&amp; SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\n",
            "254941790757601280\t557103111\tnegative\tThey may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\n",
            "264169034155696130\t382403760\tneutral\tIm bringing the monster load of candy tomorrow, I just hope it doesn't get all squiched\n",
            "263192091700654080\t344222239\tobjective-OR-neutral\tApple software, retail chiefs out in overhaul: SAN FRANCISCO Apple Inc CEO Tim Cook on Monday replaced the heads... http://t.co/X49ZEOsG\n",
            "263398998675693568\t812957996\tpositive\t@oluoch @victor_otti @kunjand I just watched it! Sridevi's comeback.... U remember her from the 90s?? Sun mornings on NTA ;)\n",
            "260200142420992000\t332530284\tobjective\t#Livewire Nadal confirmed for Mexican Open in February: Rafael Nadal is set to play at the Me... http://t.co/zgUXpcnC #LiveWireAthletics\n",
            "264087629237202944\t61903760\tpositive\t@MsSheLahY I didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked\n"
          ]
        }
      ],
      "source": [
        "# This is a tab seperated file, so with csv reader use delimiter=\"\\t\"\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/week-9-lab/sentiment-twitter-data.tsv') as in_file:\n",
        "    count = 0\n",
        "    for row in in_file:\n",
        "        print(row.strip())\n",
        "        count += 1\n",
        "        if count == 10:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lvgpjKBBBqgZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "673cc91b-1249-4200-a58c-8c6c682d1650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8002 8002\n",
            "[\"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\"\n",
            " \"Iranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\"\n",
            " 'with J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.'\n",
            " ...\n",
            " 'All Blue and White fam, we r meeting at Golden Corral for dinner tonight at 6pm....'\n",
            " '@DariusButler28   Have a great game agaist Tampa Bay tonight.'\n",
            " \"I'm pisseeedddd that I missed Kid Cudi's show in Dallas, it was trending worldwide that night, &all Im hearing is positive reviews of lolla\"]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "X_txt = []\n",
        "\n",
        "y= []\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/week-9-lab/sentiment-twitter-data.tsv') as in_file:\n",
        "\n",
        "  iCSV = csv.reader(in_file, delimiter='\\t')\n",
        "\n",
        "  for row in iCSV:\n",
        "    X_txt.append(row[-1])\n",
        "    y.append(row[2])\n",
        "\n",
        "print(len(X_txt),len(y))\n",
        "\n",
        "\n",
        "\n",
        "X_txt = np.array(X_txt)\n",
        "\n",
        "y = np.array(y)\n",
        "#Write code here\n",
        "\n",
        "print(X_txt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(32)\n",
        "import random\n",
        "random.seed(32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_txt_train, X_txt_test, y_train, y_test = train_test_split(X_txt, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "C63v9vKGi3b5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec = CountVectorizer(ngram_range = (1,2), min_df = 3)\n",
        "\n",
        "X_train = vec.fit_transform(X_txt_train)\n",
        "\n",
        "X_test = vec.transform (X_txt_test)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R7fbpxwhiVqc",
        "outputId": "5a8e4ad2-c48a-4221-82d9-3b96373fb8a6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6401, 9929) (1601, 9929)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC()\n",
        "\n",
        "params ={\"C\": [0.001, 0.01, 0.1, 1.0,10]}\n",
        "\n",
        "clf = GridSearchCV(svc,params, cv=3)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KmWaCNipkS9N",
        "outputId": "536e99ea-0361-4a3b-c69c-caf986c9d935"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=LinearSVC(),\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10]})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PbUElCMIlKWs",
        "outputId": "f6811af7-a640-4426-c0de-0e49323de995"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44633811837691956"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a6szydcplN9y",
        "outputId": "d3d3b7c9-6a0c-45e2-ab83-756b6841b0da"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.46283572767020614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict(X_train)\n",
        "print(accuracy_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Rj4rtkRHmVlt",
        "outputId": "13f55277-6ec6-4881-cacc-90095ad7d167"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function accuracy_score at 0x7f397382a8c0>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}